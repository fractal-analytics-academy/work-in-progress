{
  "cells": [
    {
      "metadata": {
        "collapsed": true
      },
      "cell_type": "markdown",
      "source": "# Learning Spark using Azure Databricks"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import os\nfilenames = os.listdir('./imgs')\n#os.listdir('../input/images02')",
      "execution_count": 17,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "filenames",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 18,
          "data": {
            "text/plain": "['img-02.png',\n 'img-without-bkgrnd-02.png',\n 'test.gif',\n 'img-without-bkgrnd-01.png',\n 'img-01.png',\n 'img-without-bkgrnd-03.png']"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Hi, This is me!\n![Image](./imgs/img-without-bkgrnd-04.png)"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "<html lang=\"en\" class=\"no-js\">\n<body>\n    <div>\n        <div>\n            <h1>My Learning Notebooks</h1>\n\t\t\t<p>Learn code in fun way!</p>\n\t\t</div>\n        <div>\n\t\t\t<img src=\"./imgs/img-without-bkgrnd-04.png\">\n\t\t</div>\n\t</div>\n</body>\n</html>"
    },
    {
      "metadata": {
        "trusted": true,
        "scrolled": true
      },
      "cell_type": "code",
      "source": "from IPython.display import HTML\nHTML('<img src=\"./imgs/img-without-bkgrnd-04.png\">')",
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 25,
          "data": {
            "text/html": "<img src=\"./imgs/img-without-bkgrnd-04.png\">",
            "text/plain": "<IPython.core.display.HTML object>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import imageio\nimages = []\nfor filename in filenames:\n    images.append(imageio.imread('./imgs/'+filename))\nimageio.mimsave('./imgs/test.gif', images,fps=2)",
      "execution_count": 14,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Questions to Answer\nðŸ‘‰ Why should we start thinking about working on Spark? <br><br>\nðŸ‘‰ When Hadoop systems were doing so well in Big data processing space, why did we need something like Spark? <br><br>\nðŸ‘‰ When do we decide to move to Spark? <br><br>\nðŸ‘‰ How to design a data processing pipeline using Spark? <br><br>\nðŸ‘‰ How to launch Databricks on Azure? <br><br>\nðŸ‘‰ How to create a cluster on Databricks? <br><br>\nðŸ‘‰ How to start a new notebook on Databricks and associate it with a cluster? <br><br>\nðŸ‘‰ How to read some data in Spark? <br><br>\nðŸ‘‰ What are the data structures supported on Spark? <br><br>\nðŸ‘‰ What are the various data sources from which data can be read using Spark? <br><br>\nðŸ‘‰ How to read data from these different data sources? <br><br>\nðŸ‘‰ What all data wrangling operations can we perform using Spark? <br><br>\nðŸ‘‰ We talk about Transitions and Actions when we talk about Spark. What are they? <br><br>\nðŸ‘‰ What's lazy processing in Spark? <br><br>\nðŸ‘‰ How to connect to Spark from PowerBI and build visuals? <br><br>\nðŸ‘‰ How to do machine learning on Spark?"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "markdown",
      "source": "### Activities To Do\nðŸ‘‰ Find out the system configuration of your Azure notebook machine <br><br>\nðŸ‘‰ Perform a data pre-processing activity on Azure notebooks and measure the performance (The problem set will be given to you) <br><br>\nðŸ‘‰ Perform the same set of data pre-processing activities on Apache Spark using Azure Databricks and measure the performance <br><br>\nðŸ‘‰ Compare the two performance measures and discuss the reasons <br><br>\nðŸ‘‰ Perform below set of data processing activities on Spark :\n   * Read data from multiple data sources :\n       * Read data from a SQL Server Database\n       * Read data from Azure Blob Storage\n       * Read data from HDFS\n   * Try the following data-structures to read data in Spark : \n       * RDDs\n       * DataFrames\n       * Datasets\n   * Merge dataframes of huge size\n   * Filter dataframes\n   * Group-by & Aggregate (MapReduce)\n   * Create a Spark job\n   * Schedule a Spark job, run the job and consume the data in PowerBI"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "markdown",
      "source": "### Q) What is the available configuration of free tier of provisioned Azure Notebook?\n![Here](./imgs/img-01.png)"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "markdown",
      "source": "# Important Notes : \n* We will download dataset from **[this](http://stat-computing.org/dataexpo/2009/the-data.html)** link to our Azure Notebook machines <br><br>\n* **Instructions :** <br>\n    **Step-1 :** Go to your project terminal : Click [here](https://workinprogress-fractalanalyticsacademy.notebooks.azure.com/j/terminals/1)<br>\n    **Step-2 :** Go to library folder : type `cd library` on the linux console <br>\n    **Step-3 :** Run this command to check CPU configurations : `lscpu` <br>\n    **Step-4 :** Run this command to check Memory configurations : `free`, use `free -m` to check the available memory in megabytes <br>\n    **Step-5 :** Run this command to check available storage : `lsblk` <br>\n    **Step-6 :** Create a new folder called **data** : `mkdir data` <br>\n    **Step-7 :** Pull airline on-time performance data (for the year 1987) from the URL mentioned above as follows : <br>\n    `wget http://stat-computing.org/dataexpo/2009/1987.csv.bz2` <br>\n    **Step-8 :** Uzip the `.bz2` file using this command : `bzip2 -dk 1987.csv.bz2` <br>\n    **Step-9 :** Repeat steps 7 and 8 for file **1988.csv.bz2** <br>"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python36",
      "display_name": "Python 3.6",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}