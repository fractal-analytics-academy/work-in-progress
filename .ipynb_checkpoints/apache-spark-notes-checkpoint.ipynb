{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Learning Spark using Azure Databricks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "filenames = os.listdir('./imgs')\n",
    "#os.listdir('../input/images02')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['img-02.png',\n",
       " 'img-without-bkgrnd-02.png',\n",
       " 'test.gif',\n",
       " 'img-without-bkgrnd-01.png',\n",
       " 'img-01.png',\n",
       " 'img-without-bkgrnd-03.png']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filenames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hi, This is me!\n",
    "![Image](./imgs/img-without-bkgrnd-04.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<html lang=\"en\" class=\"no-js\">\n",
    "<body>\n",
    "    <div>\n",
    "        <div>\n",
    "            <h1>My Learning Notebooks</h1>\n",
    "\t\t\t<p>Learn code in fun way!</p>\n",
    "\t\t</div>\n",
    "        <div>\n",
    "\t\t\t<img src=\"./imgs/img-without-bkgrnd-04.png\">\n",
    "\t\t</div>\n",
    "\t</div>\n",
    "</body>\n",
    "</html>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"./imgs/img-without-bkgrnd-04.png\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "HTML('<img src=\"./imgs/img-without-bkgrnd-04.png\">')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "images = []\n",
    "for filename in filenames:\n",
    "    images.append(imageio.imread('./imgs/'+filename))\n",
    "imageio.mimsave('./imgs/test.gif', images,fps=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions to Answer\n",
    "ðŸ‘‰ Why should we start thinking about working on Spark? <br><br>\n",
    "ðŸ‘‰ When Hadoop systems were doing so well in Big data processing space, why did we need something like Spark? <br><br>\n",
    "ðŸ‘‰ When do we decide to move to Spark? <br><br>\n",
    "ðŸ‘‰ How to design a data processing pipeline using Spark? <br><br>\n",
    "ðŸ‘‰ How to launch Databricks on Azure? <br><br>\n",
    "ðŸ‘‰ How to create a cluster on Databricks? <br><br>\n",
    "ðŸ‘‰ How to start a new notebook on Databricks and associate it with a cluster? <br><br>\n",
    "ðŸ‘‰ How to read some data in Spark? <br><br>\n",
    "ðŸ‘‰ What are the data structures supported on Spark? <br><br>\n",
    "ðŸ‘‰ What are the various data sources from which data can be read using Spark? <br><br>\n",
    "ðŸ‘‰ How to read data from these different data sources? <br><br>\n",
    "ðŸ‘‰ What all data wrangling operations can we perform using Spark? <br><br>\n",
    "ðŸ‘‰ We talk about Transitions and Actions when we talk about Spark. What are they? <br><br>\n",
    "ðŸ‘‰ What's lazy processing in Spark? <br><br>\n",
    "ðŸ‘‰ How to connect to Spark from PowerBI and build visuals? <br><br>\n",
    "ðŸ‘‰ How to do machine learning on Spark?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activities To Do\n",
    "ðŸ‘‰ Find out the system configuration of your Azure notebook machine <br><br>\n",
    "ðŸ‘‰ Perform a data pre-processing activity on Azure notebooks and measure the performance (The problem set will be given to you) <br><br>\n",
    "ðŸ‘‰ Perform the same set of data pre-processing activities on Apache Spark using Azure Databricks and measure the performance <br><br>\n",
    "ðŸ‘‰ Compare the two performance measures and discuss the reasons <br><br>\n",
    "ðŸ‘‰ Perform below set of data processing activities on Spark :\n",
    "   * Read data from multiple data sources :\n",
    "       * Read data from a SQL Server Database\n",
    "       * Read data from Azure Blob Storage\n",
    "       * Read data from HDFS\n",
    "   * Try the following data-structures to read data in Spark : \n",
    "       * RDDs\n",
    "       * DataFrames\n",
    "       * Datasets\n",
    "   * Merge dataframes of huge size\n",
    "   * Filter dataframes\n",
    "   * Group-by & Aggregate (MapReduce)\n",
    "   * Create a Spark job\n",
    "   * Schedule a Spark job, run the job and consume the data in PowerBI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q) What is the available configuration of free tier of provisioned Azure Notebook?\n",
    "![Here](./imgs/img-01.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Important Notes : \n",
    "* We will download dataset from **[this](http://stat-computing.org/dataexpo/2009/the-data.html)** link to our Azure Notebook machines <br><br>\n",
    "* **Instructions :** <br>\n",
    "    **Step-1 :** Go to your project terminal : Click [here](https://workinprogress-fractalanalyticsacademy.notebooks.azure.com/j/terminals/1)<br>\n",
    "    **Step-2 :** Go to library folder : type `cd library` on the linux console <br>\n",
    "    **Step-3 :** Run this command to check CPU configurations : `lscpu` <br>\n",
    "    **Step-4 :** Run this command to check Memory configurations : `free`, use `free -m` to check the available memory in megabytes <br>\n",
    "    **Step-5 :** Run this command to check available storage : `lsblk` <br>\n",
    "    **Step-6 :** Create a new folder called **data** : `mkdir data` <br>\n",
    "    **Step-7 :** Pull airline on-time performance data (for the year 1987) from the URL mentioned above as follows : <br>\n",
    "    `wget http://stat-computing.org/dataexpo/2009/1987.csv.bz2` <br>\n",
    "    **Step-8 :** Uzip the `.bz2` file using this command : `bzip2 -dk 1987.csv.bz2` <br>\n",
    "    **Step-9 :** Repeat steps 7 and 8 for file **1988.csv.bz2** <br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
